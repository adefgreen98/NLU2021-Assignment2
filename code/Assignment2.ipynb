{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNrIjLQBGwI8uPR+mTPDceT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adefgreen98/NLU2021-Assignment2/blob/main/code/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbPe1_Qa2mDL"
      },
      "source": [
        "# Natural Language Understanding 2021 - Assignment 2: NERs & Dependency Parsing\n",
        "\n",
        "_Federico Pedeni, 223993_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY_NwBjUGRjS"
      },
      "source": [
        "### Setup\n",
        "\n",
        "The following cells are needed in order to perform automatic creation of the correct directory structure. Please deactivate it in case this is not desired."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kRn7qzwIuHj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd03fcc3-c882-4501-f5ff-7ea58efe8c86"
      },
      "source": [
        "!git clone https://github.com/adefgreen98/NLU2021-Assignment2.git\n",
        "!mv NLU2021-Assignment2/code/conll.py ./"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NLU2021-Assignment2'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 59 (delta 13), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (59/59), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYswNObrNYSu"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Extract assignment data\n",
        "if not os.path.exists('data'):\n",
        "    with zipfile.ZipFile(\"NLU2021-Assignment2/data/conll2003.zip\") as zipref:\n",
        "        zipref.extractall('data')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEAFCx3MKv7K"
      },
      "source": [
        "### Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRzLNxaCHvJs"
      },
      "source": [
        "# Needed to update spacy in Google Colab\n",
        "\n",
        "# !pip install --upgrade spacy"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSMwml0tGTOm"
      },
      "source": [
        "import itertools \n",
        "\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import sklearn\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from conll import *"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIRoEvXoQD8j",
        "outputId": "50ecd4d2-081b-4e58-caa4-afc661148dd5"
      },
      "source": [
        "\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "if spacy.__version__.startswith('3'):\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "else:\n",
        "    nlp = spacy.load('en')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (56.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fy02NlhJL1zl"
      },
      "source": [
        "### Named entity lanbels conversion from SpaCy format to CoNLL format\n",
        "\n",
        "SpaCy uses a much wider set of labels compared to the general CoNLL 4 tags. So, in order to evaluate SpaCy's parser performance, SpaCy entity tags must be converted to the CoNLL format. At this purpose, a dictionary containing a label map is declared below, which is going to be used over the execution. \n",
        "\n",
        "However, the assignment of new labels has been arbitrarily defined, since there is no official information on how to perform it. The map has been created following general information on CoNLL 2003 labels that can be found [here](https://www.clips.uantwerpen.be/conll2003/ner/annotation.txt). \n",
        "\n",
        "The following cell has been used to gather information for label conversions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAeb10wJWasZ",
        "outputId": "35916506-03c2-48b0-bec0-8a2ac1cc7792"
      },
      "source": [
        "if spacy.__version__.startswith('3'):\n",
        "    for el in nlp.meta[\"labels\"][\"ner\"]:\n",
        "        print(el, \": \", spacy.explain(el))\n",
        "else:\n",
        "    for el in nlp.entity.labels:\n",
        "        print(el, \": \", spacy.explain(el))\n",
        "    \n",
        "for el in nlp.meta[\"labels\"][\"ner\"]:\n",
        "    print(el, \": \", spacy.explain(el))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CARDINAL :  Numerals that do not fall under another type\n",
            "DATE :  Absolute or relative dates or periods\n",
            "EVENT :  Named hurricanes, battles, wars, sports events, etc.\n",
            "FAC :  Buildings, airports, highways, bridges, etc.\n",
            "GPE :  Countries, cities, states\n",
            "LANGUAGE :  Any named language\n",
            "LAW :  Named documents made into laws.\n",
            "LOC :  Non-GPE locations, mountain ranges, bodies of water\n",
            "MONEY :  Monetary values, including unit\n",
            "NORP :  Nationalities or religious or political groups\n",
            "ORDINAL :  \"first\", \"second\", etc.\n",
            "ORG :  Companies, agencies, institutions, etc.\n",
            "PERCENT :  Percentage, including \"%\"\n",
            "PERSON :  People, including fictional\n",
            "PRODUCT :  Objects, vehicles, foods, etc. (not services)\n",
            "QUANTITY :  Measurements, as of weight or distance\n",
            "TIME :  Times smaller than a day\n",
            "WORK_OF_ART :  Titles of books, songs, etc.\n",
            "CARDINAL :  Numerals that do not fall under another type\n",
            "DATE :  Absolute or relative dates or periods\n",
            "EVENT :  Named hurricanes, battles, wars, sports events, etc.\n",
            "FAC :  Buildings, airports, highways, bridges, etc.\n",
            "GPE :  Countries, cities, states\n",
            "LANGUAGE :  Any named language\n",
            "LAW :  Named documents made into laws.\n",
            "LOC :  Non-GPE locations, mountain ranges, bodies of water\n",
            "MONEY :  Monetary values, including unit\n",
            "NORP :  Nationalities or religious or political groups\n",
            "ORDINAL :  \"first\", \"second\", etc.\n",
            "ORG :  Companies, agencies, institutions, etc.\n",
            "PERCENT :  Percentage, including \"%\"\n",
            "PERSON :  People, including fictional\n",
            "PRODUCT :  Objects, vehicles, foods, etc. (not services)\n",
            "QUANTITY :  Measurements, as of weight or distance\n",
            "TIME :  Times smaller than a day\n",
            "WORK_OF_ART :  Titles of books, songs, etc.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K620kf6_L0rE"
      },
      "source": [
        "\n",
        "# Labelmaps converted to CoNLL according to https://www.clips.uantwerpen.be/conll2003/ner/annotation.txt\n",
        "labelmap = {\n",
        "    'CARDINAL': 'out',\n",
        "    'DATE': 'out',\n",
        "    'EVENT': 'MISC',\n",
        "    'FAC': 'LOC',\n",
        "    'GPE': 'LOC',\n",
        "    'LANGUAGE': 'MISC',\n",
        "    'LAW': 'out',\n",
        "    'LOC': 'LOC',\n",
        "    'MONEY': 'out',\n",
        "    'NORP': 'MISC',\n",
        "    'ORDINAL': 'out',\n",
        "    'ORG': 'ORG',\n",
        "    'PERCENT': 'out',\n",
        "    'PERSON': 'PER',\n",
        "    'PRODUCT': 'out',\n",
        "    'QUANTITY': 'out',\n",
        "    'TIME': 'out',\n",
        "    'WORK_OF_ART': 'out',\n",
        "    '': 'out' # label for tokens that are not part of entities\n",
        "}\n",
        "\n",
        "def convert_tag(tk:spacy.tokens.Token):\n",
        "    return (tk.ent_iob_ + ('-' + labelmap[tk.ent_type_])) if labelmap[tk.ent_type_] != 'out' else 'O'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbgZAI02v0EX"
      },
      "source": [
        "### Dataset Loading\n",
        "\n",
        "For utility reasons, a custom loading function has been developed. It basically does the same thing that could do the `load()` method of `conll.py`, that is to return a list of lists representing sentences, each one containing tuples of `(token, IOBtag-label)` for tokens in the sentence. However, it also directly gets the entities per each sentence while cycling over the text dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXX04z9hF5NB"
      },
      "source": [
        "# Format of dataset: <TOKEN> <POS> <IOB part-of speech tag> <TAG>\n",
        "\n",
        "def load_dataset(mode):\n",
        "    res = {\n",
        "        'sentences': [],\n",
        "        'ners': []\n",
        "    }\n",
        "    pth = f'data/{mode}.txt'\n",
        "    \n",
        "    idx = 0\n",
        "\n",
        "    tmpsentence = []\n",
        "    tmpentity = []\n",
        "    tmp_entities_in_sentence = []\n",
        "\n",
        "    tmpmisc = None\n",
        "\n",
        "    with open(pth, 'rt') as file:\n",
        "        for line in file:\n",
        "            idx += 1\n",
        "            if line == '\\n': # arrived at the end of a sentence\n",
        "                if len(tmpsentence) > 0:\n",
        "                    # flushes the current sentence\n",
        "                    res['sentences'].append(' '.join(tmpsentence))\n",
        "                    tmpsentence = []\n",
        "\n",
        "                    # flushes the last entity in entity list for sentence\n",
        "                    if len(tmpentity) > 0: tmp_entities_in_sentence.append(tmpentity)\n",
        "                    tmpentity = []\n",
        "                    \n",
        "                    # flushes entity list\n",
        "                    res['ners'].append(tmp_entities_in_sentence)\n",
        "                    tmp_entities_in_sentence = []\n",
        "                continue\n",
        "            elif line.startswith('-DOCSTART-'): # excludes lines separating documents\n",
        "                continue\n",
        "            else:\n",
        "                if len(line.split()) != 4: \n",
        "                    print(f\"Error: line with size {len(line.split())} at index {index}\")\n",
        "                    \n",
        "                token, pos, tag1, tag2 = line.split() \n",
        "                tmpsentence.append(token)\n",
        "\n",
        "                if tag2.startswith('B'): # starts a new entity\n",
        "                    if len(tmpentity) > 0: # another one is already cached, so it must be appended\n",
        "                        tmp_entities_in_sentence.append(tmpentity)\n",
        "                        tmpentity = [(token, tag2)]\n",
        "                    else:\n",
        "                        tmpentity = [(token, tag2)]\n",
        "                elif tag2.startswith('I'): # continues current entity\n",
        "                    currtag = tag2.split('-')[1]\n",
        "                    oldtag =  tmpentity[-1][1].split('-')[1]\n",
        "                    if currtag != oldtag: \n",
        "                        raise RuntimeError(f\"not corresponding tags at index {idx}; tags are '{currtag}' (new) and '{oldtag}' (old)\")\n",
        "                    tmpentity.append((token, tag2))\n",
        "                elif tag2.startswith('O'): \n",
        "                    if len(tmpentity) > 0: tmp_entities_in_sentence.append(tmpentity)\n",
        "                    tmpentity = [(token, tag2)]\n",
        "                else:\n",
        "                    print(f\"Error: wrong tag detected at line {idx}, line: {line.encode()}\")\n",
        "\n",
        "    return res\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUQ-GcvkOX3u"
      },
      "source": [
        "dataset = load_dataset('test')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG7mczCu4eRP"
      },
      "source": [
        "### 1) Evaluate spaCy NER model using CoNLL evaluation script on CoNLL 2003 data \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7LPacoYhiJo"
      },
      "source": [
        "\n",
        "# Unique set of mapping labels to indexes (needed for sklearn.metrics.classification_report())\n",
        "# - (converted to dict for better performance, otherwise at each step would be needed list.index(token))\n",
        "__index_labels__ = [el[0] + el[1] for el in itertools.product(['B-', 'I-'], ['LOC', 'MISC', 'ORG', 'PER'])] + ['O']\n",
        "__index_labels__ = {lab: idx for lab,idx in zip(__index_labels__, range(len(__index_labels__)))}\n",
        "\n",
        "\n",
        "def retokenize(doc:spacy.tokens.Doc):\n",
        "    parsed_sent = []\n",
        "\n",
        "    # Index conversion table from token.i to CoNLL sentence index (needed for ex3)\n",
        "    # NOTE: Index-mapping is performed in an early-manner, so that it always follows actual addition to entity (ie: += tk.text) \n",
        "    #       but happens befor actual list.append() of the entity, so that the target index is increased only when list is modified\n",
        "    index_conversion_table = {}\n",
        "\n",
        "    # Multi-token entity container\n",
        "    tmpentity = ['', None]\n",
        "\n",
        "    for tk in doc:\n",
        "        # Init. variable that will be either token text or multi-token-entity concatenated tokens\n",
        "        text = None\n",
        "        \n",
        "        # label converted according to CoNLL standard (or 'O' when is not part of an entity)\n",
        "        conv_label = convert_tag(tk)\n",
        "\n",
        "        ### MULTI-TOKEN ENTITY JOIN ###\n",
        "        if len(tk.whitespace_) == 0: # current multi-entity must be expanded\n",
        "            tmpentity[0] += tk.text\n",
        "            index_conversion_table[tk.i] = len(parsed_sent)\n",
        "            \n",
        "            if tmpentity[1] is None: tmpentity[1] = conv_label \n",
        "            else:\n",
        "                if tmpentity[1] != conv_label:\n",
        "                    if tmpentity[1] == 'O' or conv_label == 'O':\n",
        "                        pass\n",
        "                    else:\n",
        "                        if tmpentity[1].split('-')[1] != conv_label.split('-')[1]: raise ValueError(\"not matching labels for sentence {}\".format(sent))\n",
        "            \n",
        "            if tk.i == (len(doc) - 1): # last multi-token entity of the sentence\n",
        "                text = tmpentity[0]\n",
        "                conv_label = tmpentity[1]\n",
        "                tmpentity = ['', None]\n",
        "            else:\n",
        "                ### NOTE: this is the core that allows to jump to next token without flushing tmpentity immediately!! ###\n",
        "                continue \n",
        "        else:\n",
        "            if len(tmpentity[0]) > 0: # cached multi-token entity is finished\n",
        "                tmpentity[0] += tk.text\n",
        "                index_conversion_table[tk.i] = len(parsed_sent)\n",
        "\n",
        "                if tmpentity[1] != conv_label:\n",
        "                    # since there are very very few (5 in test.txt) cases where multi-token entities have different tags, a rough conversion is simply applied \n",
        "                    conv_label = tmpentity[1] \n",
        "                            \n",
        "                text = tmpentity[0]\n",
        "                conv_label = tmpentity[1]\n",
        "                tmpentity = ['', None]\n",
        "            else: # no multi-token entity cached\n",
        "                text = tk.text\n",
        "                index_conversion_table[tk.i] = len(parsed_sent)\n",
        "                \n",
        "                conv_label = conv_label\n",
        "        \n",
        "        \n",
        "        parsed_sent.append((text, conv_label))\n",
        "    \n",
        "    return parsed_sent, index_conversion_table\n",
        "\n",
        "\n",
        "\n",
        "def get_accuracies(doc:spacy.tokens.Doc, ents:list, labels=__index_labels__):\n",
        "    gt_sent = [\n",
        "        # all tokens from entities in a sentence\n",
        "        [enttoken[0] for ent in ents for enttoken in ent], \n",
        "        # relative entity tags \n",
        "        [enttoken[1] for ent in ents for enttoken in ent]\n",
        "    ]\n",
        "\n",
        "    # needed for part 1\n",
        "    preds = []\n",
        "    truths = []\n",
        "\n",
        "    parsed_sent, _ = retokenize(doc)\n",
        "    \n",
        "    for text, conv_label in parsed_sent:\n",
        "        # finds correct index in sentence tokens\n",
        "        idx = gt_sent[0].index(text)\n",
        "        # finds corresponding ground truth\n",
        "        gt = gt_sent[1][idx]\n",
        "\n",
        "        # Part 1\n",
        "        preds.append(labels[conv_label])\n",
        "        truths.append(labels[gt])\n",
        "    \n",
        "    return {'part1': {'preds': preds, 'truths': truths}, 'part2': parsed_sent}\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shrNV0XsF4b6"
      },
      "source": [
        "\n",
        "### 2) Grouping of Entities. Write a function to group recognized named entities using noun_chunks method of spaCy. Analyze the groups in terms of most frequent combinations (i.e. NER types that go together).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCjktX1Dg5qs"
      },
      "source": [
        "def group_ents(doc:spacy.tokens.Doc):\n",
        "\n",
        "    res = [] # current sentence\n",
        "    \n",
        "    noun_chunks = list(doc.noun_chunks)\n",
        "    entities = list(doc.ents)\n",
        "    \n",
        "    i = 0 # index for entities\n",
        "    j = 0 # index for noun_chunks\n",
        "    \n",
        "    # iterating jointly over entities and noun chunks\n",
        "    while i < len(entities) and j < len(noun_chunks):\n",
        "        \n",
        "        # if len(entities[i]) > len(noun_chunks[j]): raise ValueError(\"mismatch with ents {} and nchunks {}\".format(entities[i], noun_chunks[j]))\n",
        "\n",
        "        # forward check on outliers entities (outside noun_chunks)\n",
        "        if entities[i][0] not in noun_chunks[j]: # if 1st token is not in current nchunk\n",
        "            \n",
        "            if (len(res) == 0 or (len(res) > 0 and len(res[-1]) > 0)): res.append([]) # start a new group, bc current one is finished\n",
        "\n",
        "            tmp = j\n",
        "            \n",
        "            while tmp < len(noun_chunks): # NOTE: supposing all items in entity belong to same noun chunk if they belong to one!!!\n",
        "                if entities[i][0] in noun_chunks[tmp]: break\n",
        "                else: tmp += 1\n",
        "\n",
        "            if tmp == len(noun_chunks): # entity is an outlier or current noun chunk does not contain entities\n",
        "                if len(res) > 0 and len(res[-1]) == 0: res[-1].append(entities[i][0].ent_type_) \n",
        "                else: res.append([entities[i][0].ent_type_])\n",
        "                if i != len(entities) - 1: res.append([]) # prepares new group (for subsequent eventually not outliers)\n",
        "                i += 1\n",
        "            else: pass # will be explored later\n",
        "        else:\n",
        "            if len(res) == 0: res.append([entities[i][0].ent_type_]) # meaning this is the first entity of a noun chunk | NOTE: supposing all items in entity have the same label!!!\n",
        "            else: res[-1].append(entities[i][0].ent_type_) # here i have already started a noun chunk, so i must append (--> actually a combination)\n",
        "            i += 1\n",
        "            j -= 1\n",
        "\n",
        "        if j == len(noun_chunks) - 1: # if it has reached the end but other entities still remain, they must be added \n",
        "            while i < len(entities):\n",
        "                if len(res[-1]) == 0: res[-1].append(entities[i][0].ent_type_)\n",
        "                else: res.append([entities[i][0].ent_type_])\n",
        "                i += 1\n",
        "        j += 1\n",
        "    \n",
        "    return res"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkEtp8oIF8_1"
      },
      "source": [
        "### 3) One of the possible post-processing steps is to fix segmentation errors. Write a function that extends the entity span to cover the full noun-compounds. Make use of compound dependency relation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Uz8vtkIR8tO"
      },
      "source": [
        "def fix_compounds(doc:spacy.tokens.Doc):\n",
        "    ents = set(doc.ents)\n",
        "    res, index_conversion_table = retokenize(doc)\n",
        "    res = [[el[0], el[1]] for el in res] # change to lists so that can be modified\n",
        "    \n",
        "    # mantained to check if another compound comes before this and has been already modified (they will be assigned the same entity.root)\n",
        "    changed = [None for el in res]\n",
        "\n",
        "    for ent in ents:\n",
        "        \n",
        "        ent_indexes = {index_conversion_table[tk.i] for tk in ent}\n",
        "        \n",
        "        # gets the correct label\n",
        "        curr_label = None\n",
        "        for i in ent_indexes:\n",
        "            if res[i][1] != 'O':\n",
        "                curr_label = res[i][1].split('-')[1]\n",
        "                break\n",
        "\n",
        "        # only executes if entity is relevant\n",
        "        if curr_label != None:\n",
        "            for tk in ent.subtree: \n",
        "\n",
        "                # if token's head is not in current entity then must be skipped\n",
        "                # NOTE: this works because usually compounds have out-to-in structure (meaning that if they belong to an entity then\n",
        "                #       their head is either referring to that entity or is their entity)\n",
        "                # Therefore, finds the first non-compound ancestor and verifies if it is inside the current entity\n",
        "                tmp = tk\n",
        "                while tmp.dep_ == 'compound':\n",
        "                    tmp = tmp.head\n",
        "                if tmp not in ent:\n",
        "                    continue\n",
        "\n",
        "                tk_converted_index = index_conversion_table[tk.i]\n",
        "                if tk.dep_ == 'compound':\n",
        "                    if tk_converted_index in ent_indexes or changed[index_conversion_table[tk.i]]: \n",
        "                        # this token is already either part of the entity or part of one of its tokens, or has already been modified as part of another entity\n",
        "                        pass\n",
        "                    else:  # not part of current entity but part of its subtree, so must fix segmentation\n",
        "                        \n",
        "                        changed[index_conversion_table[tk.i]] = ent.root\n",
        "\n",
        "                        exists_previous_compound = ent.root in changed[:index_conversion_table[tk.i]] \n",
        "                        # NOTE: only case in which the other compound is previous is checked, because we are cycling over a span ordered wrt. sentence order\n",
        "                        \n",
        "                        if tk_converted_index < index_conversion_table[ent.start]: # compound is before start of the entity\n",
        "\n",
        "                            if not exists_previous_compound: \n",
        "                                res[tk_converted_index][1] = 'B-' + curr_label # assigns the correct label to compound\n",
        "                                for i in range(index_conversion_table[ent.start], index_conversion_table[ent.end - 1]):\n",
        "                                    res[i][1] = 'I-' + curr_label\n",
        "                            else: \n",
        "                                res[tk_converted_index][1] = 'I-' + curr_label\n",
        "\n",
        "                        elif tk_converted_index > index_conversion_table[ent.end - 1]: # compound after end of the entity\n",
        "                            res[tk_converted_index] = 'I-' + curr_label\n",
        "                        \n",
        "                        else: \n",
        "                            print(ent)\n",
        "                            print(ents.difference({ent}))\n",
        "                            raise ValueError(f\"this compound token ('{tk.text}') should be inside entity span but is not, in sentence: '{doc}'\")\n",
        "        \n",
        "    return [(el[0], el[1]) for el in res]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hbLCRCgwJnT"
      },
      "source": [
        "### Results of Exercises"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yw6v9HOwMgs1"
      },
      "source": [
        "results_ex1 ={\n",
        "    'part1': {'preds': [], 'truths': []},\n",
        "    'part2': []\n",
        "}\n",
        "\n",
        "results_ex2 = []\n",
        "results_ex3 = []\n",
        "\n",
        "for sent, ents in zip(dataset['sentences'], dataset['ners']):\n",
        "    doc = nlp(sent)\n",
        "    res = get_accuracies(doc, ents)\n",
        "    results_ex1['part1']['truths'].extend(res['part1']['truths'])\n",
        "    results_ex1['part1']['preds'].extend(res['part1']['preds'])\n",
        "    results_ex1['part2'].append(res['part2'])\n",
        "\n",
        "    results_ex2.append(group_ents(doc))\n",
        "    results_ex3.append(fix_compounds(doc))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zseo4CbqSTG",
        "outputId": "17f12b94-3019-4c0d-e8a0-913e7efdd07b"
      },
      "source": [
        "sentence = 'Portuguesa 1 Atletico Mineiro 0'\n",
        "doc = nlp(sentence)\n",
        "ents = set(doc.ents)\n",
        "print([[(el.text, el.ent_iob_, el.ent_type_) for el in ent] for ent in doc.ents])\n",
        "print(*[(tk.text, tk.ent_iob_ + '-' + tk.ent_type_, tk.dep_, tk.head) for tk in doc], sep='\\n')\n",
        "print(fix_compounds(doc))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[('Portuguesa', 'B', 'ORG'), ('1', 'I', 'ORG')]]\n",
            "('Portuguesa', 'B-ORG', 'ROOT', Portuguesa)\n",
            "('1', 'I-ORG', 'nummod', Portuguesa)\n",
            "('Atletico', 'O-', 'compound', Mineiro)\n",
            "('Mineiro', 'O-', 'npadvmod', Portuguesa)\n",
            "('0', 'O-', 'punct', Mineiro)\n",
            "[('Portuguesa', 'B-ORG'), ('1', 'I-ORG'), ('Atletico', 'O'), ('Mineiro', 'O'), ('0', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxqm0dsBxc7C"
      },
      "source": [
        "#### **Exercise 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YQiVzEJLszn"
      },
      "source": [
        "\n",
        "+ report token-level performance (per class and total)\n",
        "> + accuracy of correctly recognizing all tokens that belong to named entities (i.e. tag-level accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTPsWrP2LvBE",
        "outputId": "982b2710-cddd-4f46-e52e-1754c62b22bd"
      },
      "source": [
        "print(classification_report(results_ex1['part1']['truths'], results_ex1['part1']['preds'], target_names=list(__index_labels__.keys())))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.78      0.73      0.75      1666\n",
            "      B-MISC       0.80      0.56      0.66       706\n",
            "       B-ORG       0.52      0.34      0.41      1658\n",
            "       B-PER       0.78      0.62      0.69      1615\n",
            "       I-LOC       0.53      0.59      0.56       257\n",
            "      I-MISC       0.59      0.37      0.46       214\n",
            "       I-ORG       0.43      0.53      0.47       812\n",
            "       I-PER       0.73      0.77      0.75      1158\n",
            "           O       0.95      0.98      0.97     38349\n",
            "\n",
            "    accuracy                           0.91     46435\n",
            "   macro avg       0.68      0.61      0.64     46435\n",
            "weighted avg       0.91      0.91      0.91     46435\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy4rsfL0huMJ"
      },
      "source": [
        "\n",
        "+ report CoNLL chunk-level performance (per class and total); \n",
        "> + precision, recall, f-measure of correctly recognizing all the named entities in a chunk per class and total\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6GJPq_bYrPB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "02a432a0-c85f-4d3c-d311-3db8b54be23a"
      },
      "source": [
        "# Note: List comprehension needed to extract tokens from entities, which are stored separately in lists inside dataset['ners']\n",
        "res = evaluate([[tk for ent in sent for tk in ent] for sent in dataset['ners']], results_ex1['part2'])\n",
        "pd_tbl = pd.DataFrame().from_dict(res, orient='index')\n",
        "pd_tbl.round(decimals=3)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p</th>\n",
              "      <th>r</th>\n",
              "      <th>f</th>\n",
              "      <th>s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PER</th>\n",
              "      <td>0.738</td>\n",
              "      <td>0.591</td>\n",
              "      <td>0.656</td>\n",
              "      <td>1617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MISC</th>\n",
              "      <td>0.783</td>\n",
              "      <td>0.548</td>\n",
              "      <td>0.645</td>\n",
              "      <td>702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LOC</th>\n",
              "      <td>0.776</td>\n",
              "      <td>0.719</td>\n",
              "      <td>0.746</td>\n",
              "      <td>1668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ORG</th>\n",
              "      <td>0.463</td>\n",
              "      <td>0.298</td>\n",
              "      <td>0.363</td>\n",
              "      <td>1661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total</th>\n",
              "      <td>0.690</td>\n",
              "      <td>0.537</td>\n",
              "      <td>0.604</td>\n",
              "      <td>5648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           p      r      f     s\n",
              "PER    0.738  0.591  0.656  1617\n",
              "MISC   0.783  0.548  0.645   702\n",
              "LOC    0.776  0.719  0.746  1668\n",
              "ORG    0.463  0.298  0.363  1661\n",
              "total  0.690  0.537  0.604  5648"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNkjjFTWxi8N"
      },
      "source": [
        "#### **Exercise 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "-v5YRSeLNVm_",
        "outputId": "d2ce1f13-18d0-4223-a75b-f8912a423161"
      },
      "source": [
        "def get_unique_label(group:list):\n",
        "    group.sort()\n",
        "    return \" + \".join(group)\n",
        "\n",
        "\n",
        "counts = {}\n",
        "\n",
        "for sent in results_ex2:\n",
        "    for group in sent:\n",
        "        lb = get_unique_label(group)\n",
        "        try: counts[lb] += 1\n",
        "        except KeyError: counts[lb] = 1\n",
        "\n",
        "threshold = 15\n",
        "counts = {k: v for k,v in counts.items() if v > threshold}\n",
        "counts = pd.DataFrame.from_records([{'Tag': k, 'Count': v} for k,v in counts.items()])\n",
        "\n",
        "# Plotting hist of frequencies above threshold\n",
        "plot = sn.catplot(data=counts, y='Tag', x='Count', kind='bar')\n",
        "plot.fig.subplots_adjust(top=0.92)\n",
        "plot.fig.suptitle(f\"Tag Frequencies (min. threshold {threshold})\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0.98, 'Tag Frequencies (min. threshold 15)')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bKYNFt3bt3A"
      },
      "source": [
        "#### **Exercise 3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4iWxNw8btei",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "042eb539-6e89-441a-c156-003744252f80"
      },
      "source": [
        "# NOTE: see results of Ex2 for explanation of the list comprehension\n",
        "res = evaluate([[tk for ent in sent for tk in ent] for sent in dataset['ners']], results_ex3)\n",
        "pd_tbl = pd.DataFrame().from_dict(res, orient='index')\n",
        "pd_tbl.round(decimals=3)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p</th>\n",
              "      <th>r</th>\n",
              "      <th>f</th>\n",
              "      <th>s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PER</th>\n",
              "      <td>0.595</td>\n",
              "      <td>0.482</td>\n",
              "      <td>0.533</td>\n",
              "      <td>1617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MISC</th>\n",
              "      <td>0.781</td>\n",
              "      <td>0.537</td>\n",
              "      <td>0.636</td>\n",
              "      <td>702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LOC</th>\n",
              "      <td>0.753</td>\n",
              "      <td>0.705</td>\n",
              "      <td>0.728</td>\n",
              "      <td>1668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ORG</th>\n",
              "      <td>0.439</td>\n",
              "      <td>0.282</td>\n",
              "      <td>0.344</td>\n",
              "      <td>1661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total</th>\n",
              "      <td>0.634</td>\n",
              "      <td>0.496</td>\n",
              "      <td>0.557</td>\n",
              "      <td>5648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           p      r      f     s\n",
              "PER    0.595  0.482  0.533  1617\n",
              "MISC   0.781  0.537  0.636   702\n",
              "LOC    0.753  0.705  0.728  1668\n",
              "ORG    0.439  0.282  0.344  1661\n",
              "total  0.634  0.496  0.557  5648"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nad8BE_UybEF"
      },
      "source": [
        "### Appendix: Testing Custom Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDquLvZmrhSR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "850b6787-c362-435b-ec2b-ad4bd73f467c"
      },
      "source": [
        "print(\"From load(): \", len(dataset['sentences']))\n",
        "print(\"From read_corpus_conll(): \", len(read_corpus_conll('/content/data/test.txt')))\n",
        "\n",
        "cnt = 0\n",
        "for sent in read_corpus_conll('/content/data/test.txt'):\n",
        "    if sent[0][0] == '-DOCSTART- -X- -X- O':\n",
        "        cnt += 1\n",
        "print(\"Count of unused rows in conll_load(): \", cnt)\n",
        "print(\"Difference between CoNLL load() and custom load(): \", len(read_corpus_conll('/content/data/test.txt')) - len(dataset['sentences']))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From load():  3453\n",
            "From read_corpus_conll():  3684\n",
            "Count of unused rows in conll_load():  231\n",
            "Difference between CoNLL load() and custom load():  231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POcEqW2IfNoH",
        "outputId": "69bd52bb-e5f0-4086-e826-fe232014107a"
      },
      "source": [
        "### Retokenize + Index Conversion ###\n",
        "idx = 132\n",
        "doc = nlp(dataset['sentences'][idx])\n",
        "sent, idx_table = retokenize(doc)\n",
        "print(sent)\n",
        "print({doc[k].text: sent[v] for k,v in  idx_table.items()})"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('6-0-32-2', 'O'), ('(', 'O'), ('2w', 'O'), (',', 'O'), ('1nb', 'O'), (')', 'O'), (',', 'O'), ('Saqlain', 'B-PER'), ('Mushtaq', 'I-PER'), ('8-0-54-2', 'O'), (',', 'O'), ('Mushtaq', 'B-PER'), ('Ahmad', 'I-PER')]\n",
            "{'6': ('6-0-32-2', 'O'), '-': ('8-0-54-2', 'O'), '0': ('8-0-54-2', 'O'), '32': ('6-0-32-2', 'O'), '2': ('8-0-54-2', 'O'), '(': ('(', 'O'), '2w': ('2w', 'O'), ',': (',', 'O'), '1nb': ('1nb', 'O'), ')': (')', 'O'), 'Saqlain': ('Saqlain', 'B-PER'), 'Mushtaq': ('Mushtaq', 'B-PER'), '8': ('8-0-54-2', 'O'), '54': ('8-0-54-2', 'O'), 'Ahmad': ('Ahmad', 'I-PER')}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McyXxJx868RA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d299330-4c48-4bc4-cba3-3ebbf7b18889"
      },
      "source": [
        "### Grouping entities ###\n",
        "idx = -1\n",
        "doc = nlp(dataset['sentences'][idx])\n",
        "print(doc)\n",
        "\n",
        "print([[(el.text, el.ent_iob_, el.ent_type_) for el in ent] for ent in doc.ents])\n",
        "print([[(el.text, el.ent_iob_, el.ent_type_) for el in noun_chunk] for noun_chunk in doc.noun_chunks])\n",
        "\n",
        "print(results_ex2[idx])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The lanky former Leeds United defender did not make his England debut until the age of 30 but eventually won 35 caps and was a key member of the 1966 World Cup winning team with his younger brother , Bobby .\n",
            "[[('Leeds', 'B', 'ORG'), ('United', 'I', 'ORG')], [('England', 'B', 'GPE')], [('the', 'B', 'DATE'), ('age', 'I', 'DATE'), ('of', 'I', 'DATE'), ('30', 'I', 'DATE')], [('35', 'B', 'CARDINAL')], [('1966', 'B', 'DATE')], [('World', 'B', 'EVENT'), ('Cup', 'I', 'EVENT')], [('Bobby', 'B', 'PERSON')]]\n",
            "[[('The', 'O', ''), ('lanky', 'O', ''), ('former', 'O', ''), ('Leeds', 'B', 'ORG'), ('United', 'I', 'ORG'), ('defender', 'O', '')], [('his', 'O', ''), ('England', 'B', 'GPE')], [('the', 'B', 'DATE'), ('age', 'I', 'DATE')], [('35', 'B', 'CARDINAL'), ('caps', 'O', '')], [('a', 'O', ''), ('key', 'O', ''), ('member', 'O', '')], [('the', 'O', ''), ('1966', 'B', 'DATE'), ('World', 'B', 'EVENT'), ('Cup', 'I', 'EVENT'), ('winning', 'O', ''), ('team', 'O', '')], [('his', 'O', ''), ('younger', 'O', ''), ('brother', 'O', '')], [('Bobby', 'B', 'PERSON')]]\n",
            "[['ORG'], ['GPE'], ['DATE'], ['CARDINAL'], ['DATE', 'EVENT'], ['PERSON']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD7JlseGL0ZO",
        "outputId": "0c4718fc-a82d-45e5-e2cb-0a7636493ce4"
      },
      "source": [
        "### Fixing Compounds ###\n",
        "sentence = \"my baseball bat Betty is broken .\"\n",
        "# sentence = \"He said a proposal last month by EU Farm Commissioner Franz Fischler to ban sheep brains .\"\n",
        "# sentence = dataset['sentences'][10]\n",
        "doc = nlp(sentence)\n",
        "print(doc)\n",
        "print([[(tk.text, tk.ent_iob_ + '-' + tk.ent_type_, tk.dep_) for tk in ent] for ent in doc.ents])\n",
        "print(\"-----------------------------\")\n",
        "print(*[(tk.text, tk.ent_iob_ + '-' + tk.ent_type_, tk.dep_, tk.head) for tk in doc], sep='\\n')\n",
        "print(\"-----------------------------\")\n",
        "\n",
        "print(fix_compounds(doc))\n",
        "doc.ents[0].end"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my baseball bat Betty is broken .\n",
            "[[('Betty', 'B-PERSON', 'nsubjpass')]]\n",
            "-----------------------------\n",
            "('my', 'O-', 'poss', bat)\n",
            "('baseball', 'O-', 'compound', bat)\n",
            "('bat', 'O-', 'compound', Betty)\n",
            "('Betty', 'B-PERSON', 'nsubjpass', broken)\n",
            "('is', 'O-', 'auxpass', broken)\n",
            "('broken', 'O-', 'ROOT', broken)\n",
            "('.', 'O-', 'punct', broken)\n",
            "-----------------------------\n",
            "[('my', 'O'), ('baseball', 'B-PER'), ('bat', 'I-PER'), ('Betty', 'B-PER'), ('is', 'O'), ('broken', 'O'), ('.', 'O')]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB3VORZ21Ccr"
      },
      "source": [
        "def alternative_fix_compounds(doc:spacy.tokens.Doc):\n",
        "    parsed_sent = retokenize(doc)\n",
        "    ents = list(doc.ents)\n",
        "\n",
        "    # Setting up result sentence in CoNLL format\n",
        "    res =  [[tk.text, tk.ent_iob_ + (('-' + tk.ent_type_) if tk.ent_iob_ != 'O' else '')] for tk in doc]\n",
        "    \n",
        "    # Cycling over the whole sentence\n",
        "    for tk in doc:\n",
        "        if tk.dep_ == 'compound':\n",
        "            # searching for the head entity of the compound\n",
        "            i = 0\n",
        "            while i < len(ents):\n",
        "                if tk.head in ents[i]: # performs spacy.token.Token obj. comparison, so that duplicates are avoided \n",
        "                    break\n",
        "                i += 1\n",
        "            \n",
        "            # if compound is already in entity then does not need correction;\n",
        "            # otherwise must modify iob separation of spacy\n",
        "            if i < len(ents) and tk not in ents[i]:\n",
        "                if tk.i < ents[i][0].i:\n",
        "                    res[tk.i][1] = 'B-' + ents[i][0].ent_type_\n",
        "                    for enttk in ents[i]:\n",
        "                        res[enttk.i][1] = 'I-' + enttk.ent_type_\n",
        "                    \n",
        "                elif ents[i][0].i < tk.i < ents[i][-1].i:\n",
        "                    for idx in range(tk.i + 1, ents[i][-1].i):\n",
        "                        res[idx][1] = 'I-' + ents[i][0].ent_type_\n",
        "                    res[tk.i][1] = 'I-' + ents[i][0].ent_type_\n",
        "                else: \n",
        "                    res[tk.i][1] = 'I-' + ents[i][0].ent_type_\n",
        "            \n",
        "\n",
        "    for i in range(len(res)):\n",
        "        if res[i][1] == 'O' or labelmap[res[i][1].split('-')[1]] == 'out':\n",
        "            res[i][1] = 'O'\n",
        "        else:\n",
        "            iob, tag = res[i][1].split('-')\n",
        "            res[i][1] = iob + '-' + labelmap[tag]\n",
        "        res[i] = (res[i][0], res[i][1])\n",
        "    return res"
      ],
      "execution_count": 23,
      "outputs": []
    }
  ]
}